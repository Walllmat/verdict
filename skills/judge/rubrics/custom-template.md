# [Your Domain Name] Evaluation Rubric

<!--
  HOW TO USE THIS TEMPLATE
  ========================
  1. Copy this file and rename it to match your domain (e.g., "api-design.md").
  2. Place it in the skills/judge/rubrics/ directory.
  3. Replace all bracketed placeholders [like this] with your content.
  4. Remove these comment blocks once you've filled in each section.
  5. The judge skill will automatically pick up rubrics from this directory.
-->

## Overview
<!--
  Describe what this rubric covers and when it should be used.
  Be specific about which types of skills or outputs this rubric applies to.
  Example: "This rubric evaluates API design skill outputs. Use it when the
  skill under evaluation designs REST APIs, GraphQL schemas, or gRPC services."
-->
[Describe what this rubric covers and when it should be used.]

## Dimension Criteria

<!--
  WEIGHTS MUST SUM TO 100%. The default weights below are a starting point.
  Adjust them based on what matters most in your domain.

  For each dimension:
  - Redefine "What it measures" to be specific to your domain
  - Write scoring criteria that are concrete and observable
  - Use specific examples from your domain, not generic statements
  - Ensure score levels are clearly differentiated (no overlap)
-->

### Correctness (Weight: 25%)
<!--
  What does "correct" mean in your domain?
  - For code: compiles, runs, produces expected output
  - For design: follows design principles, visually correct
  - For analysis: math is right, methods appropriate
  - For content: factually accurate, no misinformation
-->
**What it measures in this domain:** [Define correctness for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks? Be specific to your domain.] |
| 7-8   | [What earns good marks? What minor issues are acceptable?] |
| 5-6   | [What is merely acceptable? What issues start to matter?] |
| 3-4   | [What is below average? What problems are present?] |
| 1-2   | [What is poor? What fundamental failures occur?] |

### Completeness (Weight: 20%)
<!--
  What does "complete" mean in your domain?
  - For code: all features implemented, edge cases handled
  - For docs: all APIs documented, all parameters described
  - For tests: all paths covered, edge cases tested
  - For analysis: all data examined, all questions answered
-->
**What it measures in this domain:** [Define completeness for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

### Adherence (Weight: 15%)
<!--
  What does "adhering to instructions" mean in your domain?
  - Following a specific format or template
  - Using required tools, frameworks, or standards
  - Staying within scope and constraints
  - Matching a style guide or design system
-->
**What it measures in this domain:** [Define adherence for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

### Actionability (Weight: 15%)
<!--
  What does "actionable" mean in your domain?
  - For code: runs without modification, copy-paste ready
  - For docs: examples work, steps can be followed
  - For reviews: fix suggestions are specific and implementable
  - For analysis: recommendations are clear and specific
-->
**What it measures in this domain:** [Define actionability for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

### Efficiency (Weight: 10%)
<!--
  What does "efficient" mean in your domain?
  - For code: performant, no unnecessary computation
  - For content: concise, no filler, well-organized
  - For tests: no redundant tests, fast execution
  - For analysis: focused on key metrics, no noise
-->
**What it measures in this domain:** [Define efficiency for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

### Safety (Weight: 10%)
<!--
  What does "safe" mean in your domain?
  - For code: no security vulnerabilities, no data leaks
  - For content: no harmful advice, no misinformation
  - For security: no exploitation details leaked
  - For analysis: no misleading presentations, honest data
-->
**What it measures in this domain:** [Define safety for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

### Consistency (Weight: 5%)
<!--
  What does "consistent" mean in your domain?
  - Uniform quality throughout the output
  - Consistent terminology and naming
  - Aligned with historical baselines for similar tasks
  - Same standards applied to all parts of the output
-->
**What it measures in this domain:** [Define consistency for your specific domain]

| Score | Criteria |
|-------|----------|
| 9-10  | [What earns top marks?] |
| 7-8   | [What earns good marks?] |
| 5-6   | [What is acceptable?] |
| 3-4   | [What is below average?] |
| 1-2   | [What is poor?] |

## Red Flags (Auto-Deductions)
<!--
  List things that should AUTOMATICALLY reduce the score regardless of
  other qualities. These are deal-breakers specific to your domain.

  Examples:
  - Code that doesn't compile
  - Security vulnerabilities in production code
  - Factual errors in published content
  - Tests with no assertions

  Format as a bulleted list. Aim for 5-10 items.
-->
- [Red flag 1: describe what triggers an automatic deduction]
- [Red flag 2]
- [Red flag 3]
- [Red flag 4]
- [Red flag 5]

## Domain-Specific Bonuses
<!--
  List things that should earn EXTRA CREDIT in your domain. These are
  above-and-beyond qualities that distinguish exceptional output.

  Examples:
  - Proactively identifies issues not asked about
  - Provides multiple solution approaches with tradeoffs
  - Includes performance benchmarks

  Format as a bulleted list. Aim for 5-8 items.
-->
- [Bonus 1: describe what earns extra credit]
- [Bonus 2]
- [Bonus 3]
- [Bonus 4]
- [Bonus 5]
